---
title: "Data Jobs in Salt Lake City"
output:
  flexdashboard::flex_dashboard:
    orientation: columns
    vertical_layout: fill
---

```{r global, include=FALSE}
library(flexdashboard)
library(tidyverse)
library(rvest)
library(xml2)
library(digest)
library(DT) 
library(stringr)

job_scraper <- function(position = "Security Systems Engineer"){  # function can take search phrase with up to 4 words, and at least 2
  
  # Set up dataframe
  full_df <- data.frame() # Primary data frame to store info
  
  # Format search term
  word_count <- str_count(position, '\\w+')
  
  if(word_count == 2){
    search <- paste0(str_split(position, " ")[[1]][1],
                     "%20",
                     str_split(position, " ")[[1]][2])
  } else if(word_count == 3){
    search <- paste0(str_split(position, " ")[[1]][1],
                     "%20",
                     str_split(position, " ")[[1]][2],
                     "%20",
                     str_split(position, " ")[[1]][3])
  } else {
    search <- paste0(str_split(position, " ")[[1]][1],
                     "%20",
                     str_split(position, " ")[[1]][2],
                     "%20",
                     str_split(position, " ")[[1]][3],
                     "%20",
                     str_split(position, " ")[[1]][4])
  }

  #Format url
  url <- paste0("https://www.indeed.com/jobs?q=",search,"&l=Salt%20Lake%20City%2C%20UT&radius=50&fromage=2")
  
  # Read HTML
  page <- read_html(url) 
  
  # Get Job Title
  title <- page %>%
    html_nodes('.jobTitle') %>%
    html_nodes('span') %>%
    html_text('title') 
  
  title <- title[title != "new"]
  
  # Get Company Name
  company <- page %>%
    html_nodes('.companyName') %>%
    html_text('companyName')
  
  # Get Location
  location <- page %>%
    html_nodes('.companyLocation') %>%
    html_text('companyLocation')
  
  # Get Link
  link <- page %>%
    html_nodes('[data-hide-spinner = "true"]') %>%
    html_attr('href')
  
  link <- sprintf("https://www.indeed.com%s", link) 
  
  # Get Job Descriptions
  job_description <- c() # Goes into each link and pulls full text
    
    for(j in seq_along(link)) {
      
      url_link <- link[j]
      page <- xml2::read_html(url_link)
      
      job_description[j] <- page %>%
          html_nodes('.jobsearch-jobDescriptionText') %>%
          html_text()
    }
  
  # Get date
  date <- Sys.Date()
  
  # Store in dataframe
  
  ifelse(is.null(job_description),
               df <- data.frame(search = position,  date, title = NA, company = NA, location = NA, job_description = NA, link = NA),
               df <- data.frame(search = position, date, title, company, location, job_description, link))
  
  full_df <- bind_rows(full_df, df)
  
  # Clean description text and display table
  full_df$job_description <- gsub("[\r\n]", "*", full_df$job_description)

  # Create a unique id for each job posting attribute combination
  full_df$unique_id <- mapply(function(x, y, z) digest(paste0(x,y,z)), full_df$title, full_df$location, full_df$company)
  
  # Format table column names for display in dashboard
  full_df <- full_df %>% 
    select(Search = search,
           Date = date,
           Title = title,
           Company = company,
           Location = location,
           Description = job_description,
           Link = link,
           ID = unique_id) %>% 
    distinct(Link, ID, .keep_all = TRUE)
  
  list(results = full_df)

}

# job_scraper()$results

# Write empty job_data.csv once to persistent location

# job_data <- data.frame(Search = "", Date =as.Date(""), Title ="", Company ="", Location ="", Description ="", Link = "", ID = "")

# write_csv(job_data, "/opt/app-data/job_data.csv")

data <- read_csv("/opt/app-data/job_data.csv")

```

```{r, include = F}

# Find program associated with search term
  
  mscm <- c("cybersecurity analyst", "cybersecurity manager", "cybersecurity consultant",
          "chief information security officer", "director of security", "security systems engineer", 
          "cecurity analyst", "security manager", "security auditor", "security architect",
          "security consultant","information security analyst","network security engineer",
          "information security manager","security compliance analyst","penetration tester",
          "vulnerability assessment analyst")
  msis <- c("data engineer", "cloud analyst", "cloud scientist", "cloud engineer", 
          "information analyst", "development operations", "web servicing", "product management",
          "process management", "systems architecture", "software architecture")
  msba <- c("data analyst", "data scientist", "business analytics", "business intelligence")
  
  # Test
  
  job_scraper(mscm[1])$results
  job_scraper(mscm[2])$results
  job_scraper(mscm[3])$results
  job_scraper(mscm[4])$results
  job_scraper(mscm[5])$results
  job_scraper(mscm[6])$results
  job_scraper(mscm[7])$results
  job_scraper(mscm[8])$results
  job_scraper(mscm[9])$results
  job_scraper(mscm[10])$results
  job_scraper(mscm[11])$results
  job_scraper(mscm[12])$results
  job_scraper(mscm[13])$results
  job_scraper(mscm[14])$results 
  job_scraper(mscm[15])$results
  job_scraper(mscm[16])$results
  job_scraper(mscm[17])$results
  job_scraper(msis[1])$results
  job_scraper(msis[2])$results
  job_scraper(msis[3])$results
  job_scraper(msis[4])$results
  job_scraper(msis[5])$results
  job_scraper(msis[6])$results
  job_scraper(msis[7])$results
  job_scraper(msis[8])$results
  job_scraper(msis[9])$results
  job_scraper(msis[10])$results
  job_scraper(msis[11])$results 
  job_scraper(msba[1])$results 
  job_scraper(msba[2])$results 
  job_scraper(msba[3])$results 
  job_scraper(msba[4])$results
  
```
  
```{r, include = F}

# data <- read_csv("job_data.csv")

new_data <- data %>%
  bind_rows(job_scraper(mscm[1])$results) %>%
  bind_rows(job_scraper(mscm[2])$results) %>%
  bind_rows(job_scraper(mscm[3])$results) %>%
  bind_rows(job_scraper(mscm[4])$results) %>%
  bind_rows(job_scraper(mscm[5])$results) %>%
  bind_rows(job_scraper(mscm[6])$results) %>%
  bind_rows(job_scraper(mscm[7])$results) %>%
  bind_rows(job_scraper(mscm[8])$results) %>%
  bind_rows(job_scraper(mscm[9])$results) %>%
  bind_rows(job_scraper(mscm[10])$results) %>%
  bind_rows(job_scraper(mscm[11])$results) %>%
  bind_rows(job_scraper(mscm[12])$results) %>%
  bind_rows(job_scraper(mscm[13])$results) %>%
  bind_rows(job_scraper(mscm[14])$results) %>%
  bind_rows(job_scraper(mscm[15])$results) %>%
  bind_rows(job_scraper(mscm[16])$results) %>%
  bind_rows(job_scraper(mscm[17])$results) %>%
  bind_rows(job_scraper(msis[1])$results) %>%
  bind_rows(job_scraper(msis[2])$results) %>%
  bind_rows(job_scraper(msis[3])$results) %>%
  bind_rows(job_scraper(msis[4])$results) %>%
  bind_rows(job_scraper(msis[5])$results) %>%
  bind_rows(job_scraper(msis[6])$results) %>%
  bind_rows(job_scraper(msis[7])$results) %>%
  bind_rows(job_scraper(msis[8])$results) %>%
  bind_rows(job_scraper(msis[9])$results) %>%
  bind_rows(job_scraper(msis[10])$results) %>%
  bind_rows(job_scraper(msis[11])$results) %>%
  bind_rows(job_scraper(msba[1])$results) %>%
  bind_rows(job_scraper(msba[2])$results) %>%
  bind_rows(job_scraper(msba[3])$results) %>%
  bind_rows(job_scraper(msba[4])$results) %>%
  filter(!duplicated(ID),
         !grepl("United States", Location)) %>%
  mutate(Program = ifelse(Search %in% mscm, "MSCM",
                    ifelse(Search %in% msis, "MSIS", "MSBA"))) %>% 
  select(Search, Program, Date, Title, Company, Location, Description, Link, ID) %>% 
  arrange(desc(Date), Company) %>% 
  na.omit

write_csv(new_data, "/opt/app-data/job_data.csv")

```

Column {.tabset .tabset-fade}
-------------------------------------
    
### Open Positions 

```{r, fig.height=1000}
new_data$Title <- paste0("<a href='",new_data$Link,"'>",new_data$Title,"</a>")

DT::datatable(select(new_data, -Link, -ID), 
              #fillContainer = F,
              escape=F,
              options = list(pageLength = 25,
                             autoWidth = TRUE,
                             columnDefs = list(
                               list(
                                 targets = c(6),
                                 render = JS(
                                       "function(data, type, row, meta) {",
                                       "return type === 'display' && data.length > 360 ?",
                                       "'<span title=\"' + data + '\">' + data.substr(0, 360) + '...</span>' : data;",
                                       "}")))),
              callback = JS('table.page(3).draw(false);'))  %>%
  formatStyle(c("Search","Date", "Title", "Company", "Location"), "vertical-align"="top")


```
   
### Postings

```{r}
library(ggplot2)

new_data %>% 
  group_by(Date) %>% 
  count() %>% 
  ggplot(aes(Date, n))+
  geom_line()+
  theme_minimal()+
  labs(title = "Count of Job Postings by Date",
       y = "count")
  
  
```

### Text Analysis 

```{r}
library(stringr)

new_data$Description <- gsub('[[:punct:]]', ' ', new_data$Description)

new_data %>% 
  group_by(Date) %>% 
  summarize(R = sum(str_detect(string = Description, pattern = " R ")),
            Python = sum(str_detect(string = Description, pattern = " Python ") |
                          str_detect(string = Description, pattern = " python ") )) %>% 
  mutate(R = cumsum(R),
            Python = cumsum(Python)) %>% 
  pivot_longer(cols = c("R", "Python"), names_to = "Language", values_to = "count") %>% 
  ggplot(aes(Date, count, col=Language))+
  geom_line()+
  theme_minimal()+
  labs(title = "Cumulative Mentions of R vs. Python in Job Descriptions",
       y = "count")


```


  
### Job Description Topics

```{r}

```



    





