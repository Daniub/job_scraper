---
title: "Data Jobs in Salt Lake City"
output:
  flexdashboard::flex_dashboard:
    orientation: columns
    vertical_layout: fill
---

```{r resources, include=FALSE}

# Packages
library(flexdashboard)
library(tidyverse)
library(rvest)
library(xml2)
library(digest)
library(DT) 
library(stringr)

# Searches associated with programs

mscm <- c("cybersecurity analyst", "cybersecurity manager", "cybersecurity consultant",
          "chief information security officer", "director of security", "security systems engineer", 
          "security analyst", "security manager", "security auditor", "security architect",
          "security consultant","information security analyst","network security engineer",
          "information security manager","security compliance analyst","penetration tester",
          "vulnerability assessment analyst")

msis <- c("data engineer", "data architect", "cloud engineer", 
           "data warehouse analyst", "data warehouse engineer",
          "data warehouse architect","business intelligence analyst",
           "database administrator", "data integration engineer" )

msba <- c("data analyst", "data scientist")
```

```{r scraper, include = F}
job_scraper <- function(position = "director of security"){  # function can take search phrase with up to 4 words, and at least 2
  
  library(rvest)
  library(xml2)
  library(digest)
  library(tidyverse)
  
  # Format search term
  search <- gsub(pattern = " ", replacement = "%20", x = position)
  
  # Format url
  url <- paste0("https://www.indeed.com/jobs?q=",search,"&l=Salt%20Lake%20City%2C%20UT&radius=50&fromage=2")
  
  # Read HTML
  page <- xml2::read_html(url) 
  
  # Get Job Title
  title <- page %>%
    html_nodes('.jobTitle') %>%
    html_nodes('span') %>%
    html_text('title') 
  
  title <- title[title != "new"]
  
  if(length(title)==0){
    
    df <- data.frame(Search = position,
                   Date = NA, 
                   Title = NA, 
                   Company = NA, 
                   Location = NA, 
                   Link = NA,
                   Description = NA,
                   ID = NA)
    
    return(df)

 
     } else {
  
  # Get Company Name
  company <- page %>%
    html_nodes('.companyName') %>%
    html_text('companyName')
  
  # Get Location
  location <- page %>%
    html_nodes('.companyLocation') %>%
    html_text('companyLocation')
  
  # Get Link
  link <- page %>%
    html_nodes('[data-hide-spinner = "true"]') %>%
    html_attr('href')
  
  link <- paste0("https://www.indeed.com", link) 
  
  # Get Job Descriptions
  job_description <- NA # vector for descriptions
    
  # function to get description from each link
  get_description <- function(link){ 
    page <- xml2::read_html(link)
    description <- page %>%
          html_nodes('.jobsearch-jobDescriptionText') %>%
          html_text()
     ifelse(length(description) > 0, description, NA) # sometimes the description appears to be missing. if so, replace w NA
  }
  
  for(j in seq_along(link)) {
   job_description[j] <- get_description(link[j])
   Sys.sleep(1)
 }
  
  # Get date
  date <- Sys.Date()
  
  # Store jobs in dataframe and do cleaning
  
  df <- data.frame(Search = rep(position, length(job_description)),
                   Date = date, 
                   Title = title, 
                   Company = company, 
                   Location = location, 
                   Link = link,
                   Description = job_description) %>% 
    mutate(Description = gsub("[\r\n]", "*", Description), # Clean descriptions
           ID = digest(c(Title, Location, Company))) %>% #Create unique ID
    distinct(Link, ID, .keep_all = T) 
  
  return(df)
  
     }
  
  # Close open connection
   on.exit(close(url))
}
```

```{r read_data, include = F}

# Write empty job_data.csv once to persistent location

# job_data <- data.frame(Search = "", Date =as.Date(""), Title ="", Company ="", Location ="", Description ="", Link = "", ID = "")

# write_csv(job_data, "/opt/app-data/job_data.csv")

data <- read_csv("/opt/app-data/job_data.csv")

```

```{r test, include = F}

  # basic Test
  # job_scraper()
  # 
  # job_scraper(mscm[1])
  # job_scraper(mscm[2])
  # job_scraper(mscm[3])
  # job_scraper(mscm[4])
  # job_scraper(mscm[5])
  # job_scraper(mscm[6])
  # job_scraper(mscm[7])
  # job_scraper(mscm[8])
  # job_scraper(mscm[9])
  # job_scraper(mscm[10])
  # job_scraper(mscm[11])
  # job_scraper(mscm[12])
  # job_scraper(mscm[13])
  # job_scraper(mscm[14])
  # job_scraper(mscm[15])
  # job_scraper(mscm[16])
  # job_scraper(mscm[17])
  # job_scraper(msis[1])
  # job_scraper(msis[2])
  # job_scraper(msis[3])
  # job_scraper(msis[4]) #
  # job_scraper(msis[5])
  # job_scraper(msis[6])
  # job_scraper(msis[7])
  # job_scraper(msis[8])
  # job_scraper(msis[9])
  # job_scraper(msba[1])
  # job_scraper(msba[2])

  
```
  
```{r extract, include = F}

# length(mscm)
# length(msis)
# length(msbas)

new_data <- data %>%
  bind_rows(job_scraper(mscm[1])) %>%
   bind_rows(job_scraper(mscm[2])) %>%
  bind_rows(job_scraper(mscm[3])) %>%
  bind_rows(job_scraper(mscm[4])) %>%
  bind_rows(job_scraper(mscm[5])) %>%
  bind_rows(job_scraper(mscm[6])) %>%
  bind_rows(job_scraper(mscm[7])) %>%
  bind_rows(job_scraper(mscm[8])) %>%
  bind_rows(job_scraper(mscm[9])) %>%
  bind_rows(job_scraper(mscm[10])) %>%
  bind_rows(job_scraper(mscm[11])) %>%
  bind_rows(job_scraper(mscm[12])) %>%
  bind_rows(job_scraper(mscm[13])) %>%
  bind_rows(job_scraper(mscm[14])) %>%
  bind_rows(job_scraper(mscm[15])) %>%
  bind_rows(job_scraper(mscm[16])) %>%
  bind_rows(job_scraper(mscm[17])) %>%
  bind_rows(job_scraper(msis[1])) %>%
  bind_rows(job_scraper(msis[2])) %>%
  bind_rows(job_scraper(msis[3])) %>%
  bind_rows(job_scraper(msis[4])) %>%
  bind_rows(job_scraper(msis[5])) %>%
  bind_rows(job_scraper(msis[6])) %>%
  bind_rows(job_scraper(msis[7])) %>%
  bind_rows(job_scraper(msis[8]))%>%
  bind_rows(job_scraper(msis[9]))%>%
  bind_rows(job_scraper(msba[1])) %>%
  bind_rows(job_scraper(msba[2])) %>%
  filter(!duplicated(ID),
         !grepl("United States", Location),
         Company!="CyberCoders") %>%
  select(Search, Date, Title, Company, Location, Description, Link, ID) %>% 
  arrange(desc(Date), Company) %>% 
  na.omit

 write_csv(new_data, "/opt/app-data/job_data.csv")

```

Column {.tabset .tabset-fade}
-------------------------------------

### Open Positions 

```{r, fig.height=1000}


table_data <- new_data %>% 
  mutate(Program = ifelse(Search %in% mscm, "MSCM",
                    ifelse(Search %in% msis, "MSIS", "MSBA"))) %>% 
  select(Search, Program, Date, Title, Company, Location, Description, Link, ID) %>% 
  arrange(desc(Date), Company)

table_data$Title <- paste0("<a href='", table_data$Link,"'>", table_data$Title,"</a>")

DT::datatable(select(table_data, -Link, -ID),
              #fillContainer = F,
              escape=F,
              options = list(pageLength = 25,
                             autoWidth = TRUE,
                             columnDefs = list(
                               list(
                                 targets = c(7),
                                 render = JS(
                                       "function(data, type, row, meta) {",
                                       "return type === 'display' && data.length > 360 ?",
                                       "'<span title=\"' + data + '\">' + data.substr(0, 360) + '...</span>' : data;",
                                       "}")))),
              callback = JS('table.page(3).draw(false);'))  %>%
  formatStyle(c("Search","Program","Date", "Title", "Company", "Location"), "vertical-align"="top")


```
   
### Job Search Terms

**Search terms by program**: 

**MSBA**: data analyst, data scientist

**MSCM**: cybersecurity analyst, cybersecurity manager, cybersecurity consultant, chief information security officer, director of security, security systems engineer, security analyst, security manager,security auditor, security architect, security consultant, information security analyst, network security engineer, information security manager, security compliance analyst, penetration tester, vulnerability assessment analyst

**MSIS**: data engineer, data architect, cloud engineer, data warehouse analyst, data warehouse engineer, data warehouse architect, business intelligence analyst, database administrator, data integration engineer

Use the search box in the table in the Open Position tab to find specific job titles or positions  associated with programs.



### Postings


```{r}
library(ggplot2)

new_data %>% 
  group_by(Date) %>% 
  count() %>% 
  ggplot(aes(Date, n))+
  geom_line()+
  theme_minimal()+
  labs(title = "Count of Job Postings by Date",
       y = "count")
  
  
```




### Text Analysis 

```{r}
library(stringr)

new_data$Description <- gsub('[[:punct:]]', ' ', new_data$Description)

# new_data %>% 
#   group_by(Date, ID) %>% 
#   summarize(R = sum(str_detect(string = Description, pattern = " R ")),
#             Python = sum(str_detect(string = Description, pattern = " Python ") |
#                           str_detect(string = Description, pattern = " python ") ),
#             `R only` = ifelse((R > 0 & Python ==0), R, 0),
#             `Python only` = ifelse((R == 0 & Python > 0), Python, 0)) %>% 
#   group_by(Date) %>% 
#   summarize(R = sum(R),
#             Python = sum(Python),
#          `R only` = sum(`R only`),
#          `Python only` = sum(`Python only`)) %>% 
#   mutate(R = cumsum(R),
#             Python = cumsum(Python),
#          `R only` = cumsum(`R only`),
#          `Python only` = cumsum(`Python only`)) %>% 
#   pivot_longer(cols = c("R", "Python", "R only", "Python only"), 
#                names_to = "Language", 
#                values_to = "count") %>% 
#   ggplot(aes(Date, count, col=Language))+
#   geom_line()+
#   theme_minimal()+
#   labs(title = "Cumulative Mentions of R vs. Python in Job Descriptions",
#        y = "count")

new_data %>% 
  group_by(Date, ID) %>% 
  summarize(R = sum(str_detect(string = Description, pattern = " R ")),
            Python = sum(str_detect(string = Description, pattern = " Python ") |
                          str_detect(string = Description, pattern = " python "))) %>% 
  group_by(Date) %>% 
  summarize(R = sum(R),
            Python = sum(Python)) %>% 
  mutate(R = cumsum(R),
            Python = cumsum(Python)) %>% 
  pivot_longer(cols = c("R", "Python"), 
               names_to = "Language", 
               values_to = "count") %>% 
  ggplot(aes(Date, count, col=Language))+
  geom_line()+
  theme_minimal()+
  labs(title = "Cumulative Mentions of R vs. Python in Job Descriptions",
       y = "count",
       caption = "Note: additional search  terms  added on 2/17/22")


```


  
### Job Description Topics

```{r}

```



    





